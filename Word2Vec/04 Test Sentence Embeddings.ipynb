{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fse # fast sentence embeddings\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "path_w2v = '/home/santosh/Work/models/word2vec/CORD-19/'\n",
    " \n",
    "\n",
    "wv_model = KeyedVectors.load_word2vec_format(path_w2v+'CORD-10-w2v_200d_5w_10i_3mc.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load(filename):\n",
    "    file = open(path_w2v+filename+'.bin','rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def untokenize(words):\n",
    "    \"\"\"\n",
    "    Untokenizing a text undoes the tokenizing operation, restoring\n",
    "    punctuation and spaces to the places that people expect them to be.\n",
    "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
    "    except for line breaks.\n",
    "    \"\"\"\n",
    "    text = ' '.join(words)\n",
    "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
    "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
    "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
    "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
    "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
    "         \"can not\", \"cannot\")\n",
    "    step6 = step5.replace(\" ` \", \" '\")\n",
    "    step7 = step6.replace(\"[ \", \"[\").replace(\" ]\", \"]\")\n",
    "    return step7.strip()\n",
    "\n",
    "def extract_query_result(sv_query_result):\n",
    "    result_sentences =[]\n",
    "    for each_result in sv_query_result:\n",
    "        result_sentences.append(untokenize(each_result[0]))\n",
    "     \n",
    "    return result_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_index = load('sentences_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sif_sv_model = KeyedVectors.load(path_w2v+'CORD-19_sif_sv.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"pre-existing pulmonary disease SARS-Cov2 Hypertension\" \n",
    "\n",
    "# query = \"incubation days SARS-CoV\" \n",
    "# query = \"incubation days coronavirus 2019-nCoV\"#  COVID-19\n",
    "# query = 'socio economic poverty behaviour'\n",
    "\n",
    "# query = 'pre-existing diseases'\n",
    "# query = ' basic reproductive number SARS-CoV-2'\n",
    "# query = 'serial interval days'\n",
    "query = 'what do we know about drugs using to treat SARS-CoV-2'\n",
    "\n",
    "query_result = sif_sv_model.sv.similar_by_sentence(nltk.word_tokenize(query), model=sif_sv_model, indexable=sentences_index.items, topn=10000)\n",
    "\n",
    "extract_query_result(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim_sum_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scispacy]",
   "language": "python",
   "name": "conda-env-scispacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
